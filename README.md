# Continuous Probability Distributions and Markov Chains (Week 6)

### Discrete-Time Markov Chains

- Markov property
- Transition matrices
- Stationarity
- Reversibility


### Continuous Probability Distributions

- Uniform
- Normal
- Exponential
- Beta
- Gamma


### Continuous-Time Markov Chains

- Exponential waiting times
- Poisson processes
